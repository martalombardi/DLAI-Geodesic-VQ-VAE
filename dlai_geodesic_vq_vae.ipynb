{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmJuu+HaKZLKITUQ8D3V5c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martalombardi/DLAI-Geodesic-VQ-VAE/blob/main/dlai_geodesic_vq_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FIX: binary incompatibility (numpy <-> scikit-learn-extra)\n",
        "# Use pinned versions that work well together.\n",
        "# IMPORTANT: this cell restarts the kernel at the end.\n",
        "# ============================================================\n",
        "\n",
        "!pip -q uninstall -y numpy scikit-learn scikit-learn-extra\n",
        "!pip -q install \"numpy<2\" \"scikit-learn==1.3.2\" \"scikit-learn-extra==0.3.0\" scipy\n",
        "\n",
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZwXFQexjQWa",
        "outputId": "c4b507f1-f188-410d-c95a-4a726040b1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m124.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spopt 0.7.0 requires scikit-learn>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "imbalanced-learn 0.14.1 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "cuml-cu12 25.10.0 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "libpysal 4.14.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.11 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "mapclassify 2.10.0 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "esda 2.8.1 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, sklearn\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"sklearn:\", sklearn.__version__)\n",
        "print(\"KMedoids OK ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6_ciwQojSlU",
        "outputId": "26d23aa8-2e90-436d-d898-346f79577a60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy: 1.26.4\n",
            "sklearn: 1.3.2\n",
            "KMedoids OK ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BDce6dM1Noa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71da227c-3a57-4e15-c9ce-87e68380dc60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing existing repository at /content/DLAI-Geodesic-VQ-VAE\n",
            "Cloning repository...\n",
            "Cloning into 'DLAI-Geodesic-VQ-VAE'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "Receiving objects: 100% (17/17), 6.67 KiB | 3.33 MiB/s, done.\n",
            "remote: Total 17 (delta 6), reused 2 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Current working directory: /content/DLAI-Geodesic-VQ-VAE\n",
            "Repository contents:\n",
            "dlai_geodesic_vq_vae.ipynb  LICENSE  README.md\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Bootstrap: clone GitHub repository into Colab runtime\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://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@github.com/martalombardi/DLAI-Geodesic-VQ-VAE.git\"\n",
        "REPO_NAME = \"DLAI-Geodesic-VQ-VAE\"\n",
        "BASE_DIR = \"/content\"\n",
        "\n",
        "repo_path = os.path.join(BASE_DIR, REPO_NAME)\n",
        "\n",
        "# Remove existing clone (if any) to avoid conflicts\n",
        "if os.path.exists(repo_path):\n",
        "    print(f\"Removing existing repository at {repo_path}\")\n",
        "    !rm -rf \"{repo_path}\"\n",
        "\n",
        "# Clone the repository\n",
        "print(\"Cloning repository...\")\n",
        "!git clone \"{REPO_URL}\"\n",
        "\n",
        "# Move into the repository\n",
        "os.chdir(repo_path)\n",
        "\n",
        "# Sanity check\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "print(\"Repository contents:\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Continuous GridVAE (latent grid) — MNIST / FashionMNIST / CIFAR10\n",
        "# Notebook-friendly, reproducible, and formally structured.\n",
        "#\n",
        "# - Encoder/Decoder: conv stride-2 twice -> latent grid (7x7 for 28x28, 8x8 for 32x32)\n",
        "# - Decoder outputs logits (no Sigmoid) for numerical stability (BCEWithLogits).\n",
        "# - Training reports: total / recon / KL (per-sample) for both train and test.\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Reproducibility\n",
        "# ----------------------------\n",
        "def seed_everything(seed: int = 42, deterministic: bool = True) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    if deterministic:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        try:\n",
        "            torch.use_deterministic_algorithms(True)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Experiment configuration\n",
        "# ----------------------------\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    seed: int = 42\n",
        "    deterministic: bool = True\n",
        "    batch_size: int = 128\n",
        "    lr: float = 1e-3\n",
        "    epochs: int = 10\n",
        "    beta: float = 1.0\n",
        "    num_workers: int = 2\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Data loading (MNIST / FashionMNIST / CIFAR10)\n",
        "# ----------------------------\n",
        "def get_dataset_spec(name: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Returns dataset-specific parameters:\n",
        "    - torchvision dataset class\n",
        "    - image size\n",
        "    - channels\n",
        "    - recommended reconstruction loss\n",
        "    \"\"\"\n",
        "    name = name.lower()\n",
        "    if name == \"mnist\":\n",
        "        return {\"cls\": datasets.MNIST, \"size\": 28, \"channels\": 1, \"recon_loss\": \"bce\"}\n",
        "    if name in [\"fashionmnist\", \"fashion-mnist\", \"fashion_mnist\"]:\n",
        "        return {\"cls\": datasets.FashionMNIST, \"size\": 28, \"channels\": 1, \"recon_loss\": \"bce\"}\n",
        "    if name == \"cifar10\":\n",
        "        return {\"cls\": datasets.CIFAR10, \"size\": 32, \"channels\": 3, \"recon_loss\": \"mse\"}\n",
        "    raise ValueError(f\"Unsupported dataset: {name}. Use MNIST, FashionMNIST, CIFAR10.\")\n",
        "\n",
        "\n",
        "def make_dataloaders(dataset_name: str,\n",
        "                     data_root: str,\n",
        "                     batch_size: int,\n",
        "                     num_workers: int) -> Tuple[DataLoader, DataLoader, Dict]:\n",
        "    spec = get_dataset_spec(dataset_name)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((spec[\"size\"], spec[\"size\"])),\n",
        "        transforms.ToTensor(),   # keeps data in [0,1]\n",
        "    ])\n",
        "\n",
        "    train_ds = spec[\"cls\"](root=data_root, train=True, download=True, transform=transform)\n",
        "    test_ds  = spec[\"cls\"](root=data_root, train=False, download=True, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_ds, batch_size=batch_size, shuffle=False,\n",
        "        num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
        "    )\n",
        "    return train_loader, test_loader, spec\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Model definition: GridVAE\n",
        "# ----------------------------\n",
        "class GridVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Continuous VAE producing a latent grid (embedding_dim x H' x W').\n",
        "    The decoder returns logits (no sigmoid) for stable BCEWithLogits.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, embedding_dim: int = 64):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # Downsample by factor 4: 28->7, 32->8\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, embedding_dim * 2, kernel_size=3, stride=1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(embedding_dim, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(32, in_channels, kernel_size=3, stride=1, padding=1),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def reparameterize(mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = torch.chunk(h, 2, dim=1)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_logits = self.decoder(z)\n",
        "        return x_logits, mu, logvar\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Loss function\n",
        "# ----------------------------\n",
        "def vae_loss(x_logits: torch.Tensor,\n",
        "             x: torch.Tensor,\n",
        "             mu: torch.Tensor,\n",
        "             logvar: torch.Tensor,\n",
        "             recon_loss: str = \"bce\",\n",
        "             beta: float = 1.0):\n",
        "    \"\"\"\n",
        "    Returns: total, recon, kld (all SUM over batch and pixels), for later normalization.\n",
        "    \"\"\"\n",
        "    if recon_loss == \"bce\":\n",
        "        recon = F.binary_cross_entropy_with_logits(x_logits, x, reduction=\"sum\")\n",
        "    elif recon_loss == \"mse\":\n",
        "        # compare in pixel space (use sigmoid to map logits -> [0,1])\n",
        "        recon = F.mse_loss(torch.sigmoid(x_logits), x, reduction=\"sum\")\n",
        "    else:\n",
        "        raise ValueError(\"recon_loss must be 'bce' or 'mse'.\")\n",
        "\n",
        "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    total = recon + beta * kld\n",
        "    return total, recon, kld\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 6) Train & evaluate loops\n",
        "# ----------------------------\n",
        "def run_one_epoch(model, loader, optimizer, cfg: TrainConfig, recon_loss: str, train: bool):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_sum = recon_sum = kld_sum = 0.0\n",
        "\n",
        "    # Enable/disable grads\n",
        "    torch.set_grad_enabled(train)\n",
        "    for x, _ in loader:\n",
        "        x = x.to(DEVICE)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        x_logits, mu, logvar = model(x)\n",
        "        loss, recon, kld = vae_loss(x_logits, x, mu, logvar, recon_loss=recon_loss, beta=cfg.beta)\n",
        "\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_sum += loss.item()\n",
        "        recon_sum += recon.item()\n",
        "        kld_sum += kld.item()\n",
        "\n",
        "    torch.set_grad_enabled(True)\n",
        "\n",
        "    n = len(loader.dataset)\n",
        "    return (total_sum / n), (recon_sum / n), (kld_sum / n)\n",
        "\n",
        "\n",
        "def train_on_dataset(dataset_name: str,\n",
        "                     cfg: TrainConfig,\n",
        "                     data_root: str = \"./data\",\n",
        "                     embedding_dim: int = 64):\n",
        "    \"\"\"\n",
        "    Trains a GridVAE on the specified dataset and prints per-epoch metrics.\n",
        "    \"\"\"\n",
        "    train_loader, test_loader, spec = make_dataloaders(\n",
        "        dataset_name=dataset_name,\n",
        "        data_root=data_root,\n",
        "        batch_size=cfg.batch_size,\n",
        "        num_workers=cfg.num_workers\n",
        "    )\n",
        "\n",
        "    model = GridVAE(in_channels=spec[\"channels\"], embedding_dim=embedding_dim).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"DATASET: {dataset_name} | channels={spec['channels']} | size={spec['size']} | recon_loss={spec['recon_loss']}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    for epoch in range(1, cfg.epochs + 1):\n",
        "        tr_total, tr_recon, tr_kld = run_one_epoch(model, train_loader, optimizer, cfg, spec[\"recon_loss\"], train=True)\n",
        "        te_total, te_recon, te_kld = run_one_epoch(model, test_loader, optimizer, cfg, spec[\"recon_loss\"], train=False)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:02d} | \"\n",
        "            f\"Train: total={tr_total:.4f} recon={tr_recon:.4f} kld={tr_kld:.4f} | \"\n",
        "            f\"Test:  total={te_total:.4f} recon={te_recon:.4f} kld={te_kld:.4f}\"\n",
        "        )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 7) Run all 3 datasets sequentially\n",
        "# ----------------------------\n",
        "cfg = TrainConfig(\n",
        "    seed=42,\n",
        "    deterministic=True,\n",
        "    batch_size=128,\n",
        "    lr=1e-3,\n",
        "    epochs=10,     # aumenta pure a 20 quando vuoi\n",
        "    beta=1.0,\n",
        "    num_workers=2,\n",
        ")\n",
        "\n",
        "seed_everything(cfg.seed, cfg.deterministic)\n",
        "\n",
        "models = {}\n",
        "for ds in [\"MNIST\", \"FashionMNIST\", \"CIFAR10\"]:\n",
        "    models[ds] = train_on_dataset(ds, cfg, data_root=\"./data\", embedding_dim=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spcYgPnVdxRL",
        "outputId": "81dc1f43-104a-4983-bfdf-5d5d8c4290ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 486kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.49MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 15.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATASET: MNIST | channels=1 | size=28 | recon_loss=bce\n",
            "======================================================================\n",
            "Epoch 01 | Train: total=192.7869 recon=148.1763 kld=44.6105 | Test:  total=148.8501 recon=98.3906 kld=50.4594\n",
            "Epoch 02 | Train: total=136.7548 recon=87.9305 kld=48.8242 | Test:  total=131.6048 recon=83.8580 kld=47.7468\n",
            "Epoch 03 | Train: total=130.7587 recon=83.3205 kld=47.4381 | Test:  total=129.0360 recon=81.3152 kld=47.7208\n",
            "Epoch 04 | Train: total=128.8068 recon=81.8064 kld=47.0004 | Test:  total=127.3928 recon=80.8713 kld=46.5215\n",
            "Epoch 05 | Train: total=127.8114 recon=80.9866 kld=46.8248 | Test:  total=126.7313 recon=79.7407 kld=46.9907\n",
            "Epoch 06 | Train: total=126.8487 recon=80.1963 kld=46.6524 | Test:  total=126.5308 recon=80.7324 kld=45.7983\n",
            "Epoch 07 | Train: total=126.2020 recon=79.7014 kld=46.5006 | Test:  total=125.4645 recon=79.0132 kld=46.4513\n",
            "Epoch 08 | Train: total=125.7408 recon=79.3391 kld=46.4017 | Test:  total=125.1393 recon=79.5349 kld=45.6044\n",
            "Epoch 09 | Train: total=125.2177 recon=78.9595 kld=46.2583 | Test:  total=124.9174 recon=81.3391 kld=43.5783\n",
            "Epoch 10 | Train: total=124.9134 recon=78.8036 kld=46.1097 | Test:  total=124.2927 recon=78.4195 kld=45.8732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.0MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 212kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.95MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 13.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATASET: FashionMNIST | channels=1 | size=28 | recon_loss=bce\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train: total=327.1934 recon=292.1047 kld=35.0887 | Test:  total=312.4681 recon=275.5447 kld=36.9235\n",
            "Epoch 02 | Train: total=296.6275 recon=257.3473 kld=39.2802 | Test:  total=288.1103 recon=248.3747 kld=39.7357\n",
            "Epoch 03 | Train: total=284.4896 recon=243.5270 kld=40.9626 | Test:  total=284.6010 recon=244.0521 kld=40.5489\n",
            "Epoch 04 | Train: total=282.3816 recon=241.1586 kld=41.2231 | Test:  total=283.2340 recon=242.9437 kld=40.2902\n",
            "Epoch 05 | Train: total=281.1320 recon=239.9253 kld=41.2068 | Test:  total=282.3301 recon=240.6937 kld=41.6364\n",
            "Epoch 06 | Train: total=280.3599 recon=239.2094 kld=41.1506 | Test:  total=281.4668 recon=241.1906 kld=40.2762\n",
            "Epoch 07 | Train: total=279.6878 recon=238.5739 kld=41.1139 | Test:  total=281.3178 recon=240.8649 kld=40.4529\n",
            "Epoch 08 | Train: total=279.3150 recon=238.1488 kld=41.1662 | Test:  total=280.6050 recon=238.8990 kld=41.7059\n",
            "Epoch 09 | Train: total=278.9146 recon=237.7446 kld=41.1700 | Test:  total=280.1985 recon=240.0527 kld=40.1459\n",
            "Epoch 10 | Train: total=278.5213 recon=237.3469 kld=41.1744 | Test:  total=280.0808 recon=239.5402 kld=40.5406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 47.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATASET: CIFAR10 | channels=3 | size=32 | recon_loss=mse\n",
            "======================================================================\n",
            "Epoch 01 | Train: total=132.1218 recon=111.9094 kld=20.2125 | Test:  total=114.6179 recon=89.4871 kld=25.1308\n",
            "Epoch 02 | Train: total=113.1527 recon=87.1566 kld=25.9961 | Test:  total=112.4026 recon=85.6808 kld=26.7218\n",
            "Epoch 03 | Train: total=110.3136 recon=82.8661 kld=27.4475 | Test:  total=104.1332 recon=73.1979 kld=30.9353\n",
            "Epoch 04 | Train: total=101.8929 recon=69.4407 kld=32.4521 | Test:  total=100.8598 recon=67.1577 kld=33.7022\n",
            "Epoch 05 | Train: total=100.7199 recon=66.9194 kld=33.8004 | Test:  total=100.1586 recon=66.5370 kld=33.6216\n",
            "Epoch 06 | Train: total=100.2269 recon=66.0657 kld=34.1613 | Test:  total=100.1025 recon=66.5957 kld=33.5068\n",
            "Epoch 07 | Train: total=99.9377 recon=65.6250 kld=34.3128 | Test:  total=99.5198 recon=64.1603 kld=35.3595\n",
            "Epoch 08 | Train: total=99.7378 recon=65.2904 kld=34.4474 | Test:  total=99.4400 recon=64.2330 kld=35.2070\n",
            "Epoch 09 | Train: total=99.4977 recon=64.9323 kld=34.5654 | Test:  total=100.1104 recon=65.1705 kld=34.9399\n",
            "Epoch 10 | Train: total=99.4107 recon=64.7857 kld=34.6250 | Test:  total=99.1895 recon=64.2965 kld=34.8929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# A Posteriori Geodesic Quantization (Method A) — with KMedoids\n",
        "# - multi-dataset: MNIST / FashionMNIST / CIFAR10\n",
        "# - streaming extraction (no 3M vectors stored)\n",
        "# - auto latent grid size (7x7 for 28x28, 8x8 for 32x32)\n",
        "# ============================================================\n",
        "\n",
        "import os, json, time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.neighbors import kneighbors_graph, NearestNeighbors\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "from scipy.sparse.csgraph import shortest_path, connected_components\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Latents (mu) in streaming\n",
        "# ----------------------------\n",
        "def _latent_batch_mu(model, x, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = x.to(device)\n",
        "        _, mu, _ = model(x)   # mu: (B, C, H_lat, W_lat)\n",
        "    return mu\n",
        "\n",
        "def reservoir_sample_landmarks(model, loader, device, sample_size=5000, seed=42):\n",
        "    \"\"\"\n",
        "    Reservoir sampling of latent vectors without storing all vectors.\n",
        "    Returns landmarks (S,C) and latent grid size (H_lat,W_lat).\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    landmarks = None\n",
        "    seen = 0\n",
        "    H_lat = W_lat = None\n",
        "    C = None\n",
        "    n_images = 0\n",
        "\n",
        "    for x, _ in loader:\n",
        "        mu = _latent_batch_mu(model, x, device)\n",
        "        B, Cb, Hb, Wb = mu.shape\n",
        "        if landmarks is None:\n",
        "            C, H_lat, W_lat = Cb, Hb, Wb\n",
        "            landmarks = np.empty((sample_size, C), dtype=np.float32)\n",
        "\n",
        "        vecs = mu.permute(0, 2, 3, 1).reshape(-1, C).cpu().numpy().astype(np.float32)\n",
        "\n",
        "        for v in vecs:\n",
        "            if seen < sample_size:\n",
        "                landmarks[seen] = v\n",
        "            else:\n",
        "                j = rng.integers(0, seen + 1)\n",
        "                if j < sample_size:\n",
        "                    landmarks[j] = v\n",
        "            seen += 1\n",
        "\n",
        "        n_images += B\n",
        "\n",
        "    return landmarks, (H_lat, W_lat), C, n_images, seen\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Build connected kNN graph\n",
        "# ----------------------------\n",
        "def build_connected_knn_graph(X, n_neighbors=15):\n",
        "    G = kneighbors_graph(X, n_neighbors=n_neighbors, mode=\"distance\", include_self=False, n_jobs=-1)\n",
        "    G = 0.5 * (G + G.T)  # symmetrize\n",
        "\n",
        "    n_comp, labels = connected_components(G, directed=False)\n",
        "    if n_comp <= 1:\n",
        "        return G\n",
        "\n",
        "    print(f\"[WARN] kNN graph disconnected: {n_comp} components. Distances may include inf -> will be fixed.\")\n",
        "    return G\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Geodesic distances among landmarks\n",
        "# ----------------------------\n",
        "def geodesic_distances(landmarks, n_neighbors=15):\n",
        "    G = build_connected_knn_graph(landmarks, n_neighbors=n_neighbors)\n",
        "    D = shortest_path(G, directed=False, method=\"D\").astype(np.float32)\n",
        "\n",
        "    finite = np.isfinite(D)\n",
        "    if not np.all(finite):\n",
        "        max_fin = np.max(D[finite])\n",
        "        D[~finite] = max_fin * 1.1\n",
        "        print(\"[WARN] inf distances detected -> replaced with max_finite*1.1\")\n",
        "    return D\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Quantize full dataset streaming\n",
        "# ----------------------------\n",
        "def quantize_streaming(model, loader, device, landmarks, landmark_labels):\n",
        "    nn = NearestNeighbors(n_neighbors=1).fit(landmarks)\n",
        "\n",
        "    codes_all = []\n",
        "    H_lat = W_lat = None\n",
        "\n",
        "    for x, _ in loader:\n",
        "        mu = _latent_batch_mu(model, x, device)  # (B,C,H,W)\n",
        "        B, C, H, W = mu.shape\n",
        "        if H_lat is None:\n",
        "            H_lat, W_lat = H, W\n",
        "\n",
        "        vecs = mu.permute(0, 2, 3, 1).reshape(-1, C).cpu().numpy().astype(np.float32)\n",
        "        _, idx = nn.kneighbors(vecs, return_distance=True)\n",
        "        idx = idx[:, 0]\n",
        "        codes = landmark_labels[idx].reshape(B, H, W).astype(np.int32)\n",
        "        codes_all.append(codes)\n",
        "\n",
        "    return np.concatenate(codes_all, axis=0)  # (N,H,W)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# End-to-end for one dataset\n",
        "# ----------------------------\n",
        "def geodesic_quantize_method_A(\n",
        "    dataset_name: str,\n",
        "    model,\n",
        "    full_train_loader,\n",
        "    out_dir=\"results/quantizer\",\n",
        "    seed=42,\n",
        "    sample_size=5000,\n",
        "    n_neighbors=15,\n",
        "    n_codes=128,\n",
        "):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    run_tag = f\"{dataset_name}_S{sample_size}_k{n_neighbors}_K{n_codes}_seed{seed}_{int(time.time())}\"\n",
        "    save_path = os.path.join(out_dir, run_tag)\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"GEODESIC QUANTIZATION — {dataset_name}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"[A] Sampling landmarks (reservoir)...\")\n",
        "    landmarks, (H_lat, W_lat), C, n_images, total_vecs = reservoir_sample_landmarks(\n",
        "        model, full_train_loader, DEVICE, sample_size=sample_size, seed=seed\n",
        "    )\n",
        "    print(f\"Landmarks: {landmarks.shape} | latent grid: {H_lat}x{W_lat} | images: {n_images} | total vectors: {total_vecs}\")\n",
        "\n",
        "    print(\"[B] Geodesic distances among landmarks...\")\n",
        "    D_geo = geodesic_distances(landmarks, n_neighbors=n_neighbors)\n",
        "\n",
        "    print(\"[C] KMedoids on precomputed geodesic distances...\")\n",
        "    kmed = KMedoids(n_clusters=n_codes, metric=\"precomputed\", random_state=seed).fit(D_geo)\n",
        "    codebook = landmarks[kmed.medoid_indices_].astype(np.float32)\n",
        "    landmark_labels = kmed.labels_.astype(np.int32)\n",
        "    print(\"✅ Codebook:\", codebook.shape)\n",
        "\n",
        "    print(\"[D] Quantize full train set (streaming)...\")\n",
        "    codes = quantize_streaming(model, full_train_loader, DEVICE, landmarks, landmark_labels)\n",
        "    print(\"✅ Codes shape:\", codes.shape, \"(N, H_lat, W_lat)\")\n",
        "\n",
        "    meta = {\n",
        "        \"dataset\": dataset_name,\n",
        "        \"seed\": seed,\n",
        "        \"sample_size\": sample_size,\n",
        "        \"n_neighbors\": n_neighbors,\n",
        "        \"n_codes\": n_codes,\n",
        "        \"latent_grid\": [int(H_lat), int(W_lat)],\n",
        "        \"embedding_dim\": int(C),\n",
        "        \"n_images\": int(codes.shape[0]),\n",
        "    }\n",
        "    with open(os.path.join(save_path, \"meta.json\"), \"w\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "\n",
        "    np.save(os.path.join(save_path, \"landmarks.npy\"), landmarks)\n",
        "    np.save(os.path.join(save_path, \"landmark_labels.npy\"), landmark_labels)\n",
        "    np.save(os.path.join(save_path, \"codebook.npy\"), codebook)\n",
        "    np.save(os.path.join(save_path, \"codes_train.npy\"), codes)\n",
        "\n",
        "    print(f\"\\nSaved to: {save_path}\\n\")\n",
        "    return save_path\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Full train loader per dataset (shuffle=False)\n",
        "# ----------------------------\n",
        "def make_full_train_loader(dataset_name, batch_size=128, data_root=\"./data\"):\n",
        "    if dataset_name in [\"MNIST\", \"FashionMNIST\"]:\n",
        "        size = 28\n",
        "    else:\n",
        "        size = 32\n",
        "\n",
        "    tfm = transforms.Compose([transforms.Resize((size, size)), transforms.ToTensor()])\n",
        "\n",
        "    if dataset_name == \"MNIST\":\n",
        "        ds = datasets.MNIST(data_root, train=True, download=True, transform=tfm)\n",
        "    elif dataset_name == \"FashionMNIST\":\n",
        "        ds = datasets.FashionMNIST(data_root, train=True, download=True, transform=tfm)\n",
        "    elif dataset_name == \"CIFAR10\":\n",
        "        ds = datasets.CIFAR10(data_root, train=True, download=True, transform=tfm)\n",
        "    else:\n",
        "        raise ValueError(dataset_name)\n",
        "\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Run for all 3 datasets\n",
        "# Assumes you already have: models[\"MNIST\"], models[\"FashionMNIST\"], models[\"CIFAR10\"]\n",
        "# ----------------------------\n",
        "quant_cfg = {\n",
        "    \"MNIST\":        dict(sample_size=5000, n_neighbors=15, n_codes=128),\n",
        "    \"FashionMNIST\": dict(sample_size=5000, n_neighbors=20, n_codes=256),\n",
        "    \"CIFAR10\":      dict(sample_size=6000, n_neighbors=25, n_codes=512),\n",
        "}\n",
        "\n",
        "quantizer_paths = {}\n",
        "for ds in [\"MNIST\", \"FashionMNIST\", \"CIFAR10\"]:\n",
        "    full_loader = make_full_train_loader(ds, batch_size=128, data_root=\"./data\")\n",
        "    quantizer_paths[ds] = geodesic_quantize_method_A(\n",
        "        dataset_name=ds,\n",
        "        model=models[ds],\n",
        "        full_train_loader=full_loader,\n",
        "        out_dir=\"results/quantizer\",\n",
        "        seed=42,\n",
        "        **quant_cfg[ds]\n",
        "    )\n",
        "\n",
        "print(\"Done. Quantizer paths:\")\n",
        "for k, v in quantizer_paths.items():\n",
        "    print(k, \"->\", v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUpMIN56hF_Z",
        "outputId": "8a01bc65-768b-420c-d161-4b6de10a801a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "GEODESIC QUANTIZATION — MNIST\n",
            "======================================================================\n",
            "[A] Sampling landmarks (reservoir)...\n",
            "Landmarks: (5000, 64) | latent grid: 7x7 | images: 60000 | total vectors: 2940000\n",
            "[B] Geodesic distances among landmarks...\n",
            "[C] KMedoids on precomputed geodesic distances...\n",
            "✅ Codebook: (128, 64)\n",
            "[D] Quantize full train set (streaming)...\n",
            "✅ Codes shape: (60000, 7, 7) (N, H_lat, W_lat)\n",
            "\n",
            "Saved to: results/quantizer/MNIST_S5000_k15_K128_seed42_1769687155\n",
            "\n",
            "\n",
            "======================================================================\n",
            "GEODESIC QUANTIZATION — FashionMNIST\n",
            "======================================================================\n",
            "[A] Sampling landmarks (reservoir)...\n",
            "Landmarks: (5000, 64) | latent grid: 7x7 | images: 60000 | total vectors: 2940000\n",
            "[B] Geodesic distances among landmarks...\n",
            "[C] KMedoids on precomputed geodesic distances...\n",
            "✅ Codebook: (256, 64)\n",
            "[D] Quantize full train set (streaming)...\n",
            "✅ Codes shape: (60000, 7, 7) (N, H_lat, W_lat)\n",
            "\n",
            "Saved to: results/quantizer/FashionMNIST_S5000_k20_K256_seed42_1769687301\n",
            "\n",
            "\n",
            "======================================================================\n",
            "GEODESIC QUANTIZATION — CIFAR10\n",
            "======================================================================\n",
            "[A] Sampling landmarks (reservoir)...\n",
            "Landmarks: (6000, 64) | latent grid: 8x8 | images: 50000 | total vectors: 3200000\n",
            "[B] Geodesic distances among landmarks...\n",
            "[C] KMedoids on precomputed geodesic distances...\n",
            "✅ Codebook: (512, 64)\n",
            "[D] Quantize full train set (streaming)...\n",
            "✅ Codes shape: (50000, 8, 8) (N, H_lat, W_lat)\n",
            "\n",
            "Saved to: results/quantizer/CIFAR10_S6000_k25_K512_seed42_1769687455\n",
            "\n",
            "Done. Quantizer paths:\n",
            "MNIST -> results/quantizer/MNIST_S5000_k15_K128_seed42_1769687155\n",
            "FashionMNIST -> results/quantizer/FashionMNIST_S5000_k20_K256_seed42_1769687301\n",
            "CIFAR10 -> results/quantizer/CIFAR10_S6000_k25_K512_seed42_1769687455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, math, random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# =========================\n",
        "# 0) Config minimale\n",
        "# =========================\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "QUANT_DIR = \"results/quantizer/MNIST_S5000_k15_K128_seed42_1769687155\"   # <-- cambia qui\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 256\n",
        "LR = 3e-4\n",
        "D_MODEL = 256\n",
        "N_HEADS = 8\n",
        "N_LAYERS = 4\n",
        "DROPOUT = 0.1\n",
        "SEED = 42\n",
        "VAL_FRAC = 0.05\n",
        "\n",
        "# =========================\n",
        "# 0b) Riproducibilità \"pratica\" (NO deterministic-algorithms su CUDA)\n",
        "#     Evita l'errore CuBLAS con MultiHeadAttention.\n",
        "# =========================\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # Non forzare determinismo totale su CUDA: causa RuntimeError con CuBLAS\n",
        "    torch.use_deterministic_algorithms(False)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "\n",
        "seed_everything(SEED)\n",
        "\n",
        "# =========================\n",
        "# 1) Carica codici + meta\n",
        "# =========================\n",
        "meta_path = os.path.join(QUANT_DIR, \"meta.json\")\n",
        "codes_path = os.path.join(QUANT_DIR, \"codes_train.npy\")\n",
        "\n",
        "assert os.path.exists(meta_path), f\"meta.json non trovato: {meta_path}\"\n",
        "assert os.path.exists(codes_path), f\"codes_train.npy non trovato: {codes_path}\"\n",
        "\n",
        "with open(meta_path, \"r\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "codes = np.load(codes_path)  # (N, H, W)\n",
        "K = int(meta[\"n_codes\"])\n",
        "H, W = meta[\"latent_grid\"]\n",
        "T = H * W\n",
        "\n",
        "BOS = K              # token di inizio sequenza\n",
        "VOCAB = K + 1        # include BOS\n",
        "\n",
        "print(\"codes:\", codes.shape, \"| K:\", K, \"| HxW:\", (H, W), \"| T:\", T, \"| device:\", DEVICE)\n",
        "\n",
        "# =========================\n",
        "# 2) Dataset (shifted)\n",
        "# =========================\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, codes_3d: np.ndarray, K: int):\n",
        "        self.codes = codes_3d.astype(np.int64)\n",
        "        self.K = K\n",
        "        self.bos = K\n",
        "        self.T = self.codes.shape[1] * self.codes.shape[2]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.codes.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        y = self.codes[idx].reshape(-1)  # (T,)\n",
        "        x = np.empty_like(y)\n",
        "        x[0] = self.bos\n",
        "        x[1:] = y[:-1]\n",
        "        return torch.from_numpy(x).long(), torch.from_numpy(y).long()\n",
        "\n",
        "# split semplice train/val (riproducibile)\n",
        "N = len(codes)\n",
        "perm = np.random.permutation(N)\n",
        "val_n = max(1, int(VAL_FRAC * N))\n",
        "val_idx = perm[:val_n]\n",
        "tr_idx  = perm[val_n:]\n",
        "\n",
        "train_ds = CodeDataset(codes[tr_idx], K)\n",
        "val_ds   = CodeDataset(codes[val_idx], K)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# =========================\n",
        "# 3) Transformer semplice (decoder-only via causal mask)\n",
        "# =========================\n",
        "class SimpleARTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size: int, K: int, T: int,\n",
        "                 d_model=256, n_heads=8, n_layers=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.K = K\n",
        "        self.T = T\n",
        "\n",
        "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = nn.Embedding(T, d_model)\n",
        "\n",
        "        enc_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.tr = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "        self.head = nn.Linear(d_model, K)  # prediciamo solo 0..K-1 (no BOS)\n",
        "\n",
        "        # causal mask (T,T): blocca il futuro\n",
        "        mask = torch.full((T, T), float(\"-inf\"))\n",
        "        mask = torch.triu(mask, diagonal=1)\n",
        "        self.register_buffer(\"causal_mask\", mask)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, T)\n",
        "        B, Tcur = x.shape\n",
        "        pos = torch.arange(Tcur, device=x.device).unsqueeze(0)  # (1,T)\n",
        "        h = self.tok_emb(x) + self.pos_emb(pos)\n",
        "        h = self.tr(h, mask=self.causal_mask[:Tcur, :Tcur])\n",
        "        h = self.ln(h)\n",
        "        logits = self.head(h)  # (B,T,K)\n",
        "        return logits\n",
        "\n",
        "model = SimpleARTransformer(\n",
        "    vocab_size=VOCAB, K=K, T=T,\n",
        "    d_model=D_MODEL, n_heads=N_HEADS, n_layers=N_LAYERS, dropout=DROPOUT\n",
        ").to(DEVICE)\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# =========================\n",
        "# 4) Train loop (semplice)\n",
        "# =========================\n",
        "def run_epoch(loader, train=True):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.set_grad_enabled(train):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "            if train:\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            logits = model(x)  # (B,T,K)\n",
        "            loss = loss_fn(logits.reshape(-1, K), y.reshape(-1))\n",
        "\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "\n",
        "    avg_loss_per_sample = total_loss / len(loader.dataset)\n",
        "    nll_per_token = avg_loss_per_sample / T\n",
        "    ppl = math.exp(min(20.0, nll_per_token))\n",
        "    return avg_loss_per_sample, ppl\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr_loss, tr_ppl = run_epoch(train_loader, train=True)\n",
        "    va_loss, va_ppl = run_epoch(val_loader, train=False)\n",
        "    print(f\"Epoch {epoch:02d} | train_loss={tr_loss:.4f} ppl={tr_ppl:.3f} | val_loss={va_loss:.4f} ppl={va_ppl:.3f}\")\n",
        "\n",
        "# =========================\n",
        "# 5) Save\n",
        "# =========================\n",
        "save_path = os.path.join(QUANT_DIR, \"transformer_prior.pt\")\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(\"Saved:\", save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5HkRHhPmvNC",
        "outputId": "6ce07912-88a1-441b-a002-d1d30f939347"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "codes: (60000, 7, 7) | K: 128 | HxW: (7, 7) | T: 49 | device: cuda\n",
            "Epoch 01 | train_loss=2.4395 ppl=1.051 | val_loss=2.0187 ppl=1.042\n",
            "Epoch 02 | train_loss=1.9278 ppl=1.040 | val_loss=1.8046 ppl=1.038\n",
            "Epoch 03 | train_loss=1.7972 ppl=1.037 | val_loss=1.7222 ppl=1.036\n",
            "Epoch 04 | train_loss=1.7297 ppl=1.036 | val_loss=1.6749 ppl=1.035\n",
            "Epoch 05 | train_loss=1.6860 ppl=1.035 | val_loss=1.6436 ppl=1.034\n",
            "Epoch 06 | train_loss=1.6530 ppl=1.034 | val_loss=1.6182 ppl=1.034\n",
            "Epoch 07 | train_loss=1.6279 ppl=1.034 | val_loss=1.6003 ppl=1.033\n",
            "Epoch 08 | train_loss=1.6070 ppl=1.033 | val_loss=1.5844 ppl=1.033\n",
            "Epoch 09 | train_loss=1.5892 ppl=1.033 | val_loss=1.5739 ppl=1.033\n",
            "Epoch 10 | train_loss=1.5738 ppl=1.033 | val_loss=1.5645 ppl=1.032\n",
            "Epoch 11 | train_loss=1.5601 ppl=1.032 | val_loss=1.5517 ppl=1.032\n",
            "Epoch 12 | train_loss=1.5478 ppl=1.032 | val_loss=1.5487 ppl=1.032\n",
            "Epoch 13 | train_loss=1.5364 ppl=1.032 | val_loss=1.5396 ppl=1.032\n",
            "Epoch 14 | train_loss=1.5267 ppl=1.032 | val_loss=1.5375 ppl=1.032\n",
            "Epoch 15 | train_loss=1.5177 ppl=1.031 | val_loss=1.5342 ppl=1.032\n",
            "Epoch 16 | train_loss=1.5087 ppl=1.031 | val_loss=1.5263 ppl=1.032\n",
            "Epoch 17 | train_loss=1.5004 ppl=1.031 | val_loss=1.5245 ppl=1.032\n",
            "Epoch 18 | train_loss=1.4929 ppl=1.031 | val_loss=1.5205 ppl=1.032\n",
            "Epoch 19 | train_loss=1.4857 ppl=1.031 | val_loss=1.5202 ppl=1.032\n",
            "Epoch 20 | train_loss=1.4793 ppl=1.031 | val_loss=1.5172 ppl=1.031\n",
            "Saved: results/quantizer/MNIST_S5000_k15_K128_seed42_1769687155/transformer_prior.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# 6) Final Generation Pipeline (Method A)\n",
        "# ============================================================\n",
        "print(f\"Generating images for dataset: {meta['dataset']}...\")\n",
        "\n",
        "# Imposta i modelli in modalità evaluation\n",
        "model.eval()  # Il tuo Transformer\n",
        "vae_model = models[meta['dataset']]\n",
        "vae_model.eval()\n",
        "\n",
        "# Carica il codebook salvato e spostalo sul DEVICE\n",
        "codebook_path = os.path.join(QUANT_DIR, \"codebook.npy\")\n",
        "codebook_np = np.load(codebook_path)\n",
        "codebook_tensor = torch.from_numpy(codebook_np).to(DEVICE)\n",
        "\n",
        "# Parametri dalla meta-configurazione\n",
        "K_codes = int(meta[\"n_codes\"])\n",
        "H_lat, W_lat = meta[\"latent_grid\"]\n",
        "T_seq = H_lat * W_lat\n",
        "BOS_token = K_codes  # Come definito nel tuo training (BOS = K)\n",
        "\n",
        "num_samples = 16\n",
        "\n",
        "# 1. Generazione sequenze autoregressive con il Transformer\n",
        "# Iniziamo con il token BOS\n",
        "generated_seqs = torch.full((num_samples, 1), BOS_token, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "print(\"Sampling tokens...\")\n",
        "for _ in range(T_seq):\n",
        "    with torch.no_grad():\n",
        "        # Il tuo modello accetta x: (B, Tcur) e applica internamente la maschera causale\n",
        "        logits = model(generated_seqs)\n",
        "\n",
        "        # Prendiamo i logits dell'ultimo step: (B, K)\n",
        "        next_token_logits = logits[:, -1, :]\n",
        "\n",
        "        # Sampling (puoi aggiungere temperatura qui se vuoi più varietà)\n",
        "        probs = F.softmax(next_token_logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Append alla sequenza\n",
        "        generated_seqs = torch.cat([generated_seqs, next_token], dim=1)\n",
        "\n",
        "# Rimuoviamo il token BOS iniziale e facciamo il reshape in griglia (H, W)\n",
        "# generated_seqs era (16, T+1), diventa (16, H, W)\n",
        "final_codes = generated_seqs[:, 1:].reshape(num_samples, H_lat, W_lat)\n",
        "\n",
        "# 2. Decoding tramite il Decoder della GridVAE\n",
        "with torch.no_grad():\n",
        "    # Trasformiamo gli indici in vettori continui usando il codebook come look-up table\n",
        "    # final_codes: (B, H, W) -> latents: (B, H, W, C)\n",
        "    latents = F.embedding(final_codes, codebook_tensor)\n",
        "\n",
        "    # GridVAE si aspetta (B, C, H, W)\n",
        "    latents = latents.permute(0, 3, 1, 2)\n",
        "\n",
        "    # Passaggio nel decoder (restituisce logits)\n",
        "    gen_logits = vae_model.decoder(latents)\n",
        "\n",
        "    # Applichiamo Sigmoid per visualizzare in [0, 1]\n",
        "    gen_images = torch.sigmoid(gen_logits).cpu()\n",
        "\n",
        "# 3. Visualizzazione\n",
        "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(8, 8))\n",
        "plt.suptitle(f\"Generated Samples - {meta['dataset']} (Method A)\")\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = gen_images[i]\n",
        "    if img.shape[0] == 1:  # MNIST / FashionMNIST\n",
        "        ax.imshow(img.squeeze(), cmap='gray')\n",
        "    else:  # CIFAR10\n",
        "        ax.imshow(img.permute(1, 2, 0))\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "WXkrHyDup5-s",
        "outputId": "68197015-6884-4150-ab4b-74d13aa6268b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating images for dataset: MNIST...\n",
            "Sampling tokens...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, math, random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# =========================\n",
        "# 0) Config minimale\n",
        "# =========================\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "QUANT_DIR = \"results/quantizer/FashionMNIST_S5000_k20_K256_seed42_1769687301\"   # <-- cambia qui\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 256\n",
        "LR = 3e-4\n",
        "D_MODEL = 256\n",
        "N_HEADS = 8\n",
        "N_LAYERS = 4\n",
        "DROPOUT = 0.1\n",
        "SEED = 42\n",
        "VAL_FRAC = 0.05\n",
        "\n",
        "# =========================\n",
        "# 0b) Riproducibilità \"pratica\" (NO deterministic-algorithms su CUDA)\n",
        "#     Evita l'errore CuBLAS con MultiHeadAttention.\n",
        "# =========================\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # Non forzare determinismo totale su CUDA: causa RuntimeError con CuBLAS\n",
        "    torch.use_deterministic_algorithms(False)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "\n",
        "seed_everything(SEED)\n",
        "\n",
        "# =========================\n",
        "# 1) Carica codici + meta\n",
        "# =========================\n",
        "meta_path = os.path.join(QUANT_DIR, \"meta.json\")\n",
        "codes_path = os.path.join(QUANT_DIR, \"codes_train.npy\")\n",
        "\n",
        "assert os.path.exists(meta_path), f\"meta.json non trovato: {meta_path}\"\n",
        "assert os.path.exists(codes_path), f\"codes_train.npy non trovato: {codes_path}\"\n",
        "\n",
        "with open(meta_path, \"r\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "codes = np.load(codes_path)  # (N, H, W)\n",
        "K = int(meta[\"n_codes\"])\n",
        "H, W = meta[\"latent_grid\"]\n",
        "T = H * W\n",
        "\n",
        "BOS = K              # token di inizio sequenza\n",
        "VOCAB = K + 1        # include BOS\n",
        "\n",
        "print(\"codes:\", codes.shape, \"| K:\", K, \"| HxW:\", (H, W), \"| T:\", T, \"| device:\", DEVICE)\n",
        "\n",
        "# =========================\n",
        "# 2) Dataset (shifted)\n",
        "# =========================\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, codes_3d: np.ndarray, K: int):\n",
        "        self.codes = codes_3d.astype(np.int64)\n",
        "        self.K = K\n",
        "        self.bos = K\n",
        "        self.T = self.codes.shape[1] * self.codes.shape[2]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.codes.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        y = self.codes[idx].reshape(-1)  # (T,)\n",
        "        x = np.empty_like(y)\n",
        "        x[0] = self.bos\n",
        "        x[1:] = y[:-1]\n",
        "        return torch.from_numpy(x).long(), torch.from_numpy(y).long()\n",
        "\n",
        "# split semplice train/val (riproducibile)\n",
        "N = len(codes)\n",
        "perm = np.random.permutation(N)\n",
        "val_n = max(1, int(VAL_FRAC * N))\n",
        "val_idx = perm[:val_n]\n",
        "tr_idx  = perm[val_n:]\n",
        "\n",
        "train_ds = CodeDataset(codes[tr_idx], K)\n",
        "val_ds   = CodeDataset(codes[val_idx], K)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# =========================\n",
        "# 3) Transformer semplice (decoder-only via causal mask)\n",
        "# =========================\n",
        "class SimpleARTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size: int, K: int, T: int,\n",
        "                 d_model=256, n_heads=8, n_layers=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.K = K\n",
        "        self.T = T\n",
        "\n",
        "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = nn.Embedding(T, d_model)\n",
        "\n",
        "        enc_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.tr = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "        self.head = nn.Linear(d_model, K)  # prediciamo solo 0..K-1 (no BOS)\n",
        "\n",
        "        # causal mask (T,T): blocca il futuro\n",
        "        mask = torch.full((T, T), float(\"-inf\"))\n",
        "        mask = torch.triu(mask, diagonal=1)\n",
        "        self.register_buffer(\"causal_mask\", mask)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, T)\n",
        "        B, Tcur = x.shape\n",
        "        pos = torch.arange(Tcur, device=x.device).unsqueeze(0)  # (1,T)\n",
        "        h = self.tok_emb(x) + self.pos_emb(pos)\n",
        "        h = self.tr(h, mask=self.causal_mask[:Tcur, :Tcur])\n",
        "        h = self.ln(h)\n",
        "        logits = self.head(h)  # (B,T,K)\n",
        "        return logits\n",
        "\n",
        "model = SimpleARTransformer(\n",
        "    vocab_size=VOCAB, K=K, T=T,\n",
        "    d_model=D_MODEL, n_heads=N_HEADS, n_layers=N_LAYERS, dropout=DROPOUT\n",
        ").to(DEVICE)\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# =========================\n",
        "# 4) Train loop (semplice)\n",
        "# =========================\n",
        "def run_epoch(loader, train=True):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.set_grad_enabled(train):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "            if train:\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            logits = model(x)  # (B,T,K)\n",
        "            loss = loss_fn(logits.reshape(-1, K), y.reshape(-1))\n",
        "\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "\n",
        "    avg_loss_per_sample = total_loss / len(loader.dataset)\n",
        "    nll_per_token = avg_loss_per_sample / T\n",
        "    ppl = math.exp(min(20.0, nll_per_token))\n",
        "    return avg_loss_per_sample, ppl\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr_loss, tr_ppl = run_epoch(train_loader, train=True)\n",
        "    va_loss, va_ppl = run_epoch(val_loader, train=False)\n",
        "    print(f\"Epoch {epoch:02d} | train_loss={tr_loss:.4f} ppl={tr_ppl:.3f} | val_loss={va_loss:.4f} ppl={va_ppl:.3f}\")\n",
        "\n",
        "# =========================\n",
        "# 5) Save\n",
        "# =========================\n",
        "save_path = os.path.join(QUANT_DIR, \"transformer_prior.pt\")\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(\"Saved:\", save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru4QBZays7G2",
        "outputId": "3a05a49a-1841-40d8-c3b4-91ca2e9d3d3d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "codes: (60000, 7, 7) | K: 256 | HxW: (7, 7) | T: 49 | device: cuda\n",
            "Epoch 01 | train_loss=2.4297 ppl=1.051 | val_loss=1.9147 ppl=1.040\n",
            "Epoch 02 | train_loss=1.8543 ppl=1.039 | val_loss=1.7349 ppl=1.036\n",
            "Epoch 03 | train_loss=1.7377 ppl=1.036 | val_loss=1.6629 ppl=1.035\n",
            "Epoch 04 | train_loss=1.6779 ppl=1.035 | val_loss=1.6142 ppl=1.033\n",
            "Epoch 05 | train_loss=1.6395 ppl=1.034 | val_loss=1.5871 ppl=1.033\n",
            "Epoch 06 | train_loss=1.6111 ppl=1.033 | val_loss=1.5671 ppl=1.032\n",
            "Epoch 07 | train_loss=1.5886 ppl=1.033 | val_loss=1.5478 ppl=1.032\n",
            "Epoch 08 | train_loss=1.5701 ppl=1.033 | val_loss=1.5408 ppl=1.032\n",
            "Epoch 09 | train_loss=1.5548 ppl=1.032 | val_loss=1.5252 ppl=1.032\n",
            "Epoch 10 | train_loss=1.5415 ppl=1.032 | val_loss=1.5196 ppl=1.031\n",
            "Epoch 11 | train_loss=1.5293 ppl=1.032 | val_loss=1.5100 ppl=1.031\n",
            "Epoch 12 | train_loss=1.5185 ppl=1.031 | val_loss=1.5033 ppl=1.031\n",
            "Epoch 13 | train_loss=1.5084 ppl=1.031 | val_loss=1.5015 ppl=1.031\n",
            "Epoch 14 | train_loss=1.4989 ppl=1.031 | val_loss=1.4973 ppl=1.031\n",
            "Epoch 15 | train_loss=1.4908 ppl=1.031 | val_loss=1.4929 ppl=1.031\n",
            "Epoch 16 | train_loss=1.4827 ppl=1.031 | val_loss=1.4914 ppl=1.031\n",
            "Epoch 17 | train_loss=1.4754 ppl=1.031 | val_loss=1.4874 ppl=1.031\n",
            "Epoch 18 | train_loss=1.4682 ppl=1.030 | val_loss=1.4830 ppl=1.031\n",
            "Epoch 19 | train_loss=1.4615 ppl=1.030 | val_loss=1.4823 ppl=1.031\n",
            "Epoch 20 | train_loss=1.4554 ppl=1.030 | val_loss=1.4790 ppl=1.031\n",
            "Saved: results/quantizer/FashionMNIST_S5000_k20_K256_seed42_1769687301/transformer_prior.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# 6) Final Generation Pipeline (Method A)\n",
        "# ============================================================\n",
        "print(f\"Generating images for dataset: {meta['dataset']}...\")\n",
        "\n",
        "# Imposta i modelli in modalità evaluation\n",
        "model.eval()  # Il tuo Transformer\n",
        "vae_model = models[meta['dataset']]\n",
        "vae_model.eval()\n",
        "\n",
        "# Carica il codebook salvato e spostalo sul DEVICE\n",
        "codebook_path = os.path.join(QUANT_DIR, \"codebook.npy\")\n",
        "codebook_np = np.load(codebook_path)\n",
        "codebook_tensor = torch.from_numpy(codebook_np).to(DEVICE)\n",
        "\n",
        "# Parametri dalla meta-configurazione\n",
        "K_codes = int(meta[\"n_codes\"])\n",
        "H_lat, W_lat = meta[\"latent_grid\"]\n",
        "T_seq = H_lat * W_lat\n",
        "BOS_token = K_codes  # Come definito nel tuo training (BOS = K)\n",
        "\n",
        "num_samples = 16\n",
        "\n",
        "# 1. Generazione sequenze autoregressive con il Transformer\n",
        "# Iniziamo con il token BOS\n",
        "generated_seqs = torch.full((num_samples, 1), BOS_token, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "print(\"Sampling tokens...\")\n",
        "for _ in range(T_seq):\n",
        "    with torch.no_grad():\n",
        "        # Il tuo modello accetta x: (B, Tcur) e applica internamente la maschera causale\n",
        "        logits = model(generated_seqs)\n",
        "\n",
        "        # Prendiamo i logits dell'ultimo step: (B, K)\n",
        "        next_token_logits = logits[:, -1, :]\n",
        "\n",
        "        # Sampling (puoi aggiungere temperatura qui se vuoi più varietà)\n",
        "        probs = F.softmax(next_token_logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Append alla sequenza\n",
        "        generated_seqs = torch.cat([generated_seqs, next_token], dim=1)\n",
        "\n",
        "# Rimuoviamo il token BOS iniziale e facciamo il reshape in griglia (H, W)\n",
        "# generated_seqs era (16, T+1), diventa (16, H, W)\n",
        "final_codes = generated_seqs[:, 1:].reshape(num_samples, H_lat, W_lat)\n",
        "\n",
        "# 2. Decoding tramite il Decoder della GridVAE\n",
        "with torch.no_grad():\n",
        "    # Trasformiamo gli indici in vettori continui usando il codebook come look-up table\n",
        "    # final_codes: (B, H, W) -> latents: (B, H, W, C)\n",
        "    latents = F.embedding(final_codes, codebook_tensor)\n",
        "\n",
        "    # GridVAE si aspetta (B, C, H, W)\n",
        "    latents = latents.permute(0, 3, 1, 2)\n",
        "\n",
        "    # Passaggio nel decoder (restituisce logits)\n",
        "    gen_logits = vae_model.decoder(latents)\n",
        "\n",
        "    # Applichiamo Sigmoid per visualizzare in [0, 1]\n",
        "    gen_images = torch.sigmoid(gen_logits).cpu()\n",
        "\n",
        "# 3. Visualizzazione\n",
        "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(8, 8))\n",
        "plt.suptitle(f\"Generated Samples - {meta['dataset']} (Method A)\")\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = gen_images[i]\n",
        "    if img.shape[0] == 1:  # MNIST / FashionMNIST\n",
        "        ax.imshow(img.squeeze(), cmap='gray')\n",
        "    else:  # CIFAR10\n",
        "        ax.imshow(img.permute(1, 2, 0))\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r7McKGxwtu8b",
        "outputId": "e58af27a-14c9-4ddb-a5f2-7d38ea028310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating images for dataset: FashionMNIST...\n",
            "Sampling tokens...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}