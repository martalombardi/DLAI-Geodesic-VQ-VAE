{
  "N_sequences": 16,
  "seq_len": 49,
  "vocab_size": 128,
  "used_tokens": 7,
  "unused_tokens": 121,
  "pct_unused": 0.9453125,
  "token_utilization": 5.46875,
  "entropy_nats": 1.9027302793577578,
  "entropy_bits": 2.7450595381787095,
  "perplexity": 6.704173744308536,
  "effective_vocab_ratio": 0.052376357377410435,
  "token_counts": [
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    117.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    58.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    78.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    161.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    120.0,
    0.0,
    136.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    114.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0
  ],
  "per_position_used_tokens": [
    2,
    3,
    4,
    4,
    4,
    3,
    4,
    2,
    3,
    5,
    4,
    4,
    4,
    4,
    4,
    5,
    5,
    5,
    6,
    5,
    4,
    3,
    6,
    6,
    4,
    7,
    5,
    4,
    3,
    5,
    5,
    5,
    4,
    5,
    4,
    2,
    5,
    6,
    6,
    5,
    5,
    3,
    3,
    5,
    7,
    6,
    6,
    5,
    2
  ],
  "per_position_perplexity": [
    1.7547653506033232,
    2.4602329762891006,
    3.014496776569348,
    3.014496776569348,
    2.2756491157934366,
    2.296537423407359,
    3.198557201172535,
    1.4575692649810905,
    2.01963929931604,
    4.682298795999885,
    3.6880445006132034,
    2.8891378922424016,
    2.2756491157934366,
    3.604006848712048,
    2.831594094719484,
    4.436424665235825,
    3.4695215263554946,
    4.3123031257009705,
    3.9093186572230967,
    4.3123031257009705,
    2.6829030848013256,
    2.8387205126507524,
    5.474850352293471,
    5.106083043687101,
    3.6880445006132034,
    5.753330987107182,
    3.9301973370990355,
    2.5876468925581615,
    2.649351128562104,
    4.060851361608244,
    4.366915066037587,
    3.9301973370990355,
    2.925726559967319,
    3.668016172818685,
    3.014496776569348,
    1.8609486313308101,
    4.085857990775222,
    5.5923652650542035,
    5.106083043687101,
    4.285910587006902,
    3.8713038100882717,
    1.589490554357095,
    2.175942995894572,
    4.366915066037587,
    5.5923652650542035,
    4.4283898110380315,
    4.67381863664292,
    4.366915066037587,
    1.2633812503027273
  ],
  "per_position_summary": {
    "used_tokens_min": 2,
    "used_tokens_mean": 4.408163265306122,
    "used_tokens_max": 7,
    "ppl_min": 1.2633812503027273,
    "ppl_mean": 3.5069299106077176,
    "ppl_max": 5.753330987107182
  },
  "run_id": "generation_vqvae_bc1p00_vw1p00_K128_refined_seed123_temp0p70_tp0p85_cs1p15",
  "metric_tag": "vqvae_bc1p00_vw1p00_K128",
  "sampler_tag": "refined",
  "seed": 123,
  "user_tag": "generation",
  "temperature": 0.7,
  "top_p": 0.85,
  "codebook_scale": 1.15
}