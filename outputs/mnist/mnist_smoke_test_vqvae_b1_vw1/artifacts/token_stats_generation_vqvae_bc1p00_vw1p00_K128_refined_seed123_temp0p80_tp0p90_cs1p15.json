{
  "N_sequences": 16,
  "seq_len": 49,
  "vocab_size": 128,
  "used_tokens": 7,
  "unused_tokens": 121,
  "pct_unused": 0.9453125,
  "token_utilization": 5.46875,
  "entropy_nats": 1.9114361837915106,
  "entropy_bits": 2.7576195033317377,
  "perplexity": 6.762794443082806,
  "effective_vocab_ratio": 0.052834331586584425,
  "token_counts": [
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    111.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    69.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    81.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    148.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    117.0,
    0.0,
    154.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    104.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0
  ],
  "per_position_used_tokens": [
    2,
    4,
    6,
    4,
    3,
    3,
    4,
    3,
    3,
    5,
    5,
    3,
    5,
    5,
    4,
    5,
    4,
    6,
    5,
    5,
    4,
    3,
    5,
    6,
    4,
    6,
    5,
    4,
    4,
    6,
    5,
    6,
    6,
    6,
    4,
    3,
    6,
    5,
    6,
    5,
    5,
    3,
    3,
    6,
    6,
    6,
    6,
    5,
    2
  ],
  "per_position_perplexity": [
    1.7547653506033232,
    3.014496776569347,
    4.4283898110380315,
    3.6040068487120487,
    2.0867794400977164,
    2.675366828465664,
    3.198557201172535,
    1.825627880057923,
    2.513040641334882,
    4.782801987708333,
    4.858931393520616,
    2.649351128562104,
    2.8218489457419005,
    4.366915066037587,
    3.509530701206646,
    4.366915066037587,
    3.198557201172535,
    5.474850352293471,
    3.4695215263554946,
    4.531650292231522,
    2.504391818580872,
    2.8387205126507515,
    4.531650292231522,
    5.389070770225886,
    3.0792014356780038,
    5.5923652650542035,
    4.155541640365934,
    2.831594094719484,
    3.47299345510468,
    5.128221559132067,
    4.436424665235825,
    5.106083043687101,
    4.36203093066103,
    3.9093186572230967,
    2.925726559967319,
    2.578111495150432,
    5.298702257124208,
    4.682298795999885,
    4.67381863664292,
    4.682298795999884,
    4.148015496294371,
    1.589490554357095,
    2.3743888938571454,
    5.275827777072008,
    4.963225915211198,
    5.215682551402702,
    5.568223042771739,
    3.7467482975009925,
    1.2633812503027273
  ],
  "per_position_summary": {
    "used_tokens_min": 2,
    "used_tokens_mean": 4.591836734693878,
    "used_tokens_max": 6,
    "ppl_min": 1.2633812503027273,
    "ppl_mean": 3.784805161206619,
    "ppl_max": 5.5923652650542035
  },
  "run_id": "generation_vqvae_bc1p00_vw1p00_K128_refined_seed123_temp0p80_tp0p90_cs1p15",
  "metric_tag": "vqvae_bc1p00_vw1p00_K128",
  "sampler_tag": "refined",
  "seed": 123,
  "user_tag": "generation",
  "temperature": 0.8,
  "top_p": 0.9,
  "codebook_scale": 1.15
}